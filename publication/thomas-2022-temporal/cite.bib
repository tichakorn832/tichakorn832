@inproceedings{Thomas:2022:Temporal,
 abstract = {The function approximators employed by traditional image-based Deep Reinforcement Learning (DRL) algorithms usually lack a temporal learning component and instead focus on learning the spatial component. We propose a technique, Temporal Shift Reinforcement Learning (TSRL), wherein both temporal, as well as spatial components are jointly learned. Moreover, TSRL does not require additional parameters to perform temporal learning. We show that TSRL outperforms the commonly used frame stacking heuristic on all of the Atari environments we test on while beating the SOTA for all except one of them. This investigation has implications in the robotics as well as sequential decision-making domains. Our code is available at - https://github.com/Deepakgthomas/TSM_RL},
 address = {New York, NY, USA},
 author = {Thomas, Deepak George and Wongpiromsarn, Tichakorn and Jannesari, Ali},
 booktitle = {Proceedings of the 2nd European Workshop on Machine Learning and Systems},
 doi = {10.1145/3517207.3526968},
 isbn = {9781450392549},
 keywords = {sample efficiency, deep reinforcement learning},
 location = {Rennes, France},
 numpages = {6},
 pages = {95â€“100},
 publisher = {Association for Computing Machinery},
 series = {EuroMLSys '22},
 title = {Temporal Shift Reinforcement Learning},
 year = {2022}
}

