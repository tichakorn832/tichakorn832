<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Motion planning | Tichakorn (Nok) Wongpiromsarn</title>
    <link>https://tichakorn832.github.io/tag/motion-planning/</link>
      <atom:link href="https://tichakorn832.github.io/tag/motion-planning/index.xml" rel="self" type="application/rss+xml" />
    <description>Motion planning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 15 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://tichakorn832.github.io/img/nok.png</url>
      <title>Motion planning</title>
      <link>https://tichakorn832.github.io/tag/motion-planning/</link>
    </image>
    
    <item>
      <title>Sharing the World with Autonomous Systems: What Goes Wrong and How to Fix It (NSF)</title>
      <link>https://tichakorn832.github.io/project/inconsistencies/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://tichakorn832.github.io/project/inconsistencies/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Award Number:&lt;/strong&gt; CNS-2211141&lt;br /&gt;
&lt;strong&gt;Amount:&lt;/strong&gt; 599,854&lt;br /&gt;
&lt;strong&gt;Start Date:&lt;/strong&gt; 06/15/2022&lt;br /&gt;
&lt;strong&gt;End Date:&lt;/strong&gt; 05/31/2025&lt;br /&gt;
&lt;strong&gt;Collaborators:&lt;/strong&gt; 
&lt;a href=&#34;http://www.ae.utexas.edu/facultysites/topcu/wiki/index.php/Main_Page&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ufuk Topcu&lt;/a&gt; (UT Austin)&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;As autonomous systems start to operate in open, uncontrolled environments alongside humans, safety becomes a major concern. In applications in which human-operated systems and autonomous systems are in close interaction, the heterogeneity causes different agents to exhibit different behaviors under the same situation due to the differences in how they see the world and make decisions. For example, autonomous vehicles tend to be more conservative than average human drivers, leading to instances of confusion and frustration of human drivers when encountering an autonomous vehicle. As a result, understanding the effects of inconsistencies among interacting agents on the overall system is critical for the adoption and acceptance of autonomous systems.&lt;/p&gt;
&lt;p&gt;This project aims to develop novel algorithms that will quantitatively and succinctly characterize the sources and effects of inconsistencies in perception and decision-making among the interacting agents. Based on this characterization, the project will develop efficient synthesis algorithms for autonomous systems to actively identify the inconsistencies and influence the behaviors of the other agents to improve the safety of the overall system. A key innovation lies in a rigorous approach integrating probabilistic formal methods, games on graphs, joint perception and planning, and convex optimization. While the resulting algorithms will be applicable to a wide range of cyber-physical systems, demonstrations will leverage an experimental platform in which autonomous vehicles interact with each other as well as human-controlled vehicles in mockup urban environments. The project will likewise promote outreach to industry, regulatory agencies, and the broader cyber-physical system (CPS) community through technical short courses. All educational material, demonstrations and software generated by the project will be shared publicly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CAREER: Establishing Correctness of Learning-Enabled Autonomous Systems with Conflicting Requirements (NSF)</title>
      <link>https://tichakorn832.github.io/project/correctness-autonomy/</link>
      <pubDate>Tue, 15 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://tichakorn832.github.io/project/correctness-autonomy/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Award Number:&lt;/strong&gt; CNS-2141153&lt;br /&gt;
&lt;strong&gt;Amount:&lt;/strong&gt; 502,352&lt;br /&gt;
&lt;strong&gt;Start Date:&lt;/strong&gt; 02/15/2022&lt;br /&gt;
&lt;strong&gt;End Date:&lt;/strong&gt; 01/31/2027&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Autonomous systems are subject to multiple regulatory requirements due to their safety-critical nature. In general, it is infeasible to guarantee the satisfaction of all requirements under all conditions. In such situations, the system needs to decide how to prioritize among them. Two main factors complicate this decision. First, the priorities among the conflicting requirements may not be fully established. Second, the decision needs to be made under uncertainties arising from both the learning-based components within the system and the unstructured, unpredictable, and non-cooperating nature of the environments. Therefore, establishing the correctness of autonomous systems requires specification languages that capture the unequal importance of the requirements, quantify the violation of each requirement, and incorporate uncertainties faced by the systems.&lt;/p&gt;
&lt;p&gt;The proposed effort targets a major gap in theoretical foundations and computational tools to enable practical applications of formal methods throughout the development process of autonomous systems that include learning-based components, operate in uncertain environments, and are subject to conflicting requirements with partially established priorities. Its key novelty lies in the development of (1) probabilistic rulebooks, a new specification formalism that captures the tradeoffs between the uncertainty and the degree of violation of the requirements and utilizes such violation risk together with partially established priorities among the requirements to establish a consistent order among the trajectories of the system, (2) minimum-violation control synthesis algorithms that minimize the total violation risk based on the probabilistic rulebooks and allow learning-based functionality to be incorporated in a provably correct manner, and (3) quantitative verification frameworks that utilize statistical analysis of the learning-based components and the environment as well as the probabilistic rulebooks to provide quantitative analysis of the system. Such development will serve as a critical step towards establishing assurance of autonomous systems. This project will validate the theoretical results and algorithms developed under the proposed effort on a small autonomy platform that will also be utilized for educational purposes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Planning with Conflicting Specifications</title>
      <link>https://tichakorn832.github.io/project/planning-conflicting-specifications/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://tichakorn832.github.io/project/planning-conflicting-specifications/</guid>
      <description>&lt;p&gt;Autonomous systems may be subject to several requirements. Consider, as an example, autonomous vehicles that need to follow the road rules. Often, these rules cannot be simultaneously satisfied. For instance, when encoutering a vehicle that is (improperly) parked next to the solid line, an autonomous vehicle may need to violate the lane keeping rule (which prohibits the vehicle from crossing solid lane boundary) or the obstacle clearance rule (which requires the vehicle to keep some safety gap when passing a parked vehicle). Another example is the 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Trolley_problem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;trolley problem&lt;/a&gt; where autonomous systems need to choose which safety requirements to violate. More complications arise when taking into account uncertainties, e.g., in perception, prediction, control, etc.&lt;/p&gt;
&lt;p&gt;The goal of this project is to develop planning and decision-making algorithms for systems that are subject to multiple, potentially conflicting objectives. These objectives may be represented by a combination of cost functions (e.g., control efforts) and temporal logic formulas (e.g., rules of the road), with associated violation metrics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Abstraction-Based Multi-Vehicle Command and Control</title>
      <link>https://tichakorn832.github.io/project/planning-systems/</link>
      <pubDate>Sun, 15 Aug 2004 00:00:00 +0000</pubDate>
      <guid>https://tichakorn832.github.io/project/planning-systems/</guid>
      <description>&lt;p&gt;This work introduces an encapsulation approach to path planning for multi-vehicle control that permits other decision processes to work with simple, spatially-abstracted domain models, and partially or wholly ignore obstacles, observation uncertainty and vehicle dynamics. Application to multi-vehicle command and control has been considered.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
